---
title: Unit 11 Model Selection and Evaluation
order: 10
summary: This unit expands on model selection, evaluation, and deployment, which are critical processes in the machine learning (ML) workflow. Selecting the correct model is akin to choosing the right tool for a given prediction or classification task. However, evaluating and monitoring model performance ensures reliability and effectiveness in real-world applications. Additionally, this unit introduces MLOps (Machine Learning Operations), an essential framework for maintaining and deploying models in production environments. We will examine how automated model monitoring, retraining, and deployment pipelines enhance the robustness of ML systems.
---

[← Back to Module 3](./)

## Key topics
- The workflow of model selection, evaluation, and deployment.
- Techniques for optimising hyperparameters to enhance performance.
- Metrics beyond accuracy—choosing appropriate evaluation methods.
- MLOps concepts—ensuring model reproducibility and scalability in production.

## Notes
[Notes on Model Selection and Evaluation](../../artefacts/module-3/unit-11-notes.md)

## Readings
- **Deep Learning: Foundations and Concepts**  
  Bishop, C. and Bishop, H. (2024)  
  Cambridge University Press, UK  
  Chapter 18: Model Evaluation and Hyperparameter Tuning

- **Evaluation of Classification Models in Machine Learning**  
  Novaković, J. Dj. et al. (2017)  
  Theory and Applications of Mathematics & Computer Science, 7(1), pp. 39–46

- **Evaluating a Machine Learning Model**  
  Jordan, J. (2017)

## Artefacts
- [Model Performance and Measurment](../../artefacts/module-3/unit-11-model-performance-measurement.ipnyb)
